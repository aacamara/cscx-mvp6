## Codebase Patterns
- Express SSE requires res.flushHeaders() before streaming
- Use res.write() not res.send() for streaming
- Set Cache-Control: no-cache header
- AbortController handles client disconnects
- Anthropic SDK streaming: anthropic.messages.stream({...}) returns Stream object
- Stream events: stream.on('text', callback) for token deltas
- stream.finalMessage() returns the complete Anthropic.Message after stream ends
- WorkflowAgent.chat() at line 2724 of WorkflowAgent.ts — mirror this for chatStream()
- anthropic instance initialized at line 985-987 of WorkflowAgent.ts
- APPROVAL_REQUIRED_TOOLS list determines which tools need HITL approval
- executeReadOnlyTool() handles auto-approved tool execution
- Existing SSE infrastructure in server/src/routes/agents.ts lines 219-468 (use as reference)
- Existing SSE consumer parseSSEData in components/AIPanel/index.tsx line 226
- sendToAgentRegular() at line 885 of components/AgentControlCenter/index.tsx — this is what needs streaming
- The /api/ai/chat route at line 446 of langchain.ts — the streaming variant goes before it
- CADG detection in langchain.ts lines 479-543 — copy this logic for stream endpoint, but send as done event
- Session persistence in langchain.ts lines 546-562 — same for stream endpoint
- WorkflowAgent call in langchain.ts lines 567-614 — replace with chatStream() call
- Message types in AgentControlCenter use { agent, message, isApproval, routing, toolResults } shape
- Codebase has ~80 pre-existing type errors - focus on not introducing NEW ones
- Use `useAuth().getAuthHeaders()` for authenticated API calls
- Brand colors: cscx-accent (#e63946 red), cscx-black (#000000), cscx-gray-900 (#0a0a0a), cscx-gray-800 (#222222)
- chatStream() bypasses LangGraph graph and calls Anthropic directly — LangGraph doesn't support streaming callbacks
- System prompt in chatStream() is duplicated from callClaude() — future refactor opportunity
- WorkflowAgent.chatStream() added after chat() in WorkflowAgent class — same file, same class
- SSE streaming route at /api/ai/chat/stream added in langchain.ts BEFORE /chat route
- sendSSE() helper in langchain.ts — local to file, decoupled from agents.ts sendSSEEvent()
- CADG plans are sent as single done events (not streamed) — plan creation is fast, no need to stream
- Non-Claude fallbacks send their response as a single done event since they don't support streaming
- Always guard res.write() with clientDisconnected check to avoid "write after end" errors
- parseSSEData() in AgentControlCenter uses buffer ref for partial chunk handling — reset sseBufferRef before each new stream
- AgentMessage.isStreaming flag marks messages still receiving tokens — used for cursor/typing indicator
- sendToAgentRegular() now uses /api/ai/chat/stream — creates streaming message with unique ID, reads chunks via ReadableStream
- AbortError (DOMException name='AbortError') = user-initiated stop — don't treat as an error, keep partial content
- The `done` event content is a JSON string that must be parsed — it contains all metadata (routing, toolResults, pendingActions, CADG plan)
- CADG plans via streaming: done event with isGenerative+plan — handled identically to non-streaming, sets pendingCadgPlan
- Streaming messages use `id` field on AgentMessage to track which message to update in-place via setMessages map

---

# Streaming v2 Progress Log

Initialized: Ready to start US-001

---

## 2026-02-05 - US-001
- What was implemented: Added `chatStream()` method to WorkflowAgent class
- Files changed: `server/src/langchain/agents/WorkflowAgent.ts`
- **Details:**
  - `chatStream()` mirrors `chat()` parameters plus: `onToken` callback, `onToolEvent` callback, `abortSignal`
  - Uses `anthropic.messages.stream()` instead of `anthropic.messages.create()`
  - Listens for `text` events on stream and calls `onToken(text)` for each delta
  - After stream completes, uses `stream.finalMessage()` to get full response
  - Processes tool_use blocks identically to `callClaude()` — checks APPROVAL_REQUIRED_TOOLS, executes read-only tools, creates pendingActions
  - Calls `onToolEvent` with `tool_start`/`tool_end` around each tool execution with timing
  - Creates approval requests via approvalService for pending actions
  - Handles `abortSignal` by calling `stream.abort()` and returning empty response
  - Returns same Promise shape as `chat()`
- **Learnings for future iterations:**
  - `chat()` uses LangGraph `this.graph.invoke()` — but the actual Anthropic call is in `callClaude()` (line 2230)
  - `chatStream()` bypasses the graph and directly calls Anthropic API — necessary because LangGraph doesn't support streaming callbacks
  - The system prompt is duplicated between `callClaude()` and `chatStream()` — consider extracting to a shared function
  - `stream.abort()` can be called to cancel generation mid-stream
  - AbortSignal listeners need cleanup — use `{ once: true }` and clean up on stream end
---

## 2026-02-05 - US-002
- What was implemented: Added `POST /api/ai/chat/stream` SSE endpoint in `server/src/routes/langchain.ts`
- Files changed: `server/src/routes/langchain.ts`
- **Details:**
  - Added `sendSSE()` helper function (writes `data: JSON.stringify(event)\n\n`)
  - New route placed BEFORE existing `POST /chat` route
  - Sets SSE headers: Content-Type, Cache-Control, Connection, X-Accel-Buffering + flushHeaders()
  - Tracks client disconnect via `req.on('close')` and `req.on('aborted')`
  - CADG handling: classifies request, if generative with ≥0.7 confidence, creates plan and sends single `done` event (no streaming for CADG)
  - Session handling: same as `/chat` — getOrCreateSession(), addMessage(), getConversationHistory()
  - WorkflowAgent streaming: calls `chatStream()` with `onToken` → `{type:'token', content}` and `onToolEvent` → `{type:'tool_start'/'tool_end', ...}`
  - After stream completes, sends `done` event with full metadata JSON (response, agentType, routing, toolsUsed, toolResults, requiresApproval, pendingActions, sessionId)
  - Saves assistant response to session after stream completes
  - Non-Claude fallbacks (action handler, Google query, orchestrator) run normally and send response as single `done` event
  - Error handling: wraps everything in try/catch, sends `{type:'error', error}` then `res.end()`
  - TypeScript: `npx tsc --noEmit` passes with no NEW errors (all errors are pre-existing)
- **Learnings for future iterations:**
  - The streaming route mirrors `/chat` logic 1:1 but replaces `res.json()` with SSE events
  - CADG plans are NOT streamed — they're instant since plan creation is fast
  - Non-Claude fallbacks (Gemini-based action/Google/orchestrator handlers) don't support streaming — wrap their responses as single `done` events
  - `sendSSE()` is a local helper, not imported from agents.ts, to keep the files decoupled
  - Always check `clientDisconnected` before writing to res to avoid "write after end" errors
  - The streaming route at `/chat/stream` must be registered BEFORE `/chat` otherwise Express matches `/chat` first
---

## 2026-02-05 - US-003
- What was implemented: Added parseSSEData helper with chunk buffering and streaming state to AgentControlCenter
- Files changed: `components/AgentControlCenter/index.tsx`, `types/agents.ts`
- **Details:**
  - Added `isStreaming?: boolean` property to `AgentMessage` interface in `types/agents.ts`
  - Imported `StreamEvent` type from `types/streaming.ts` into AgentControlCenter
  - Created `parseSSEData(chunk, buffer)` utility function outside component — takes a mutable buffer object for incomplete line buffering across calls
  - Buffer logic: prepends leftover partial line from previous chunk, saves incomplete trailing line if chunk doesn't end with `\n`
  - Added streaming state inside component: `isStreaming` (useState), `abortControllerRef` (useRef<AbortController>), `streamingMessageIdRef` (useRef<string>), `sseBufferRef` (useRef<{ partial: string }>)
  - TypeScript: `npx tsc --noEmit` passes with no NEW errors (all errors are pre-existing)
- **Learnings for future iterations:**
  - `parseSSEData` is a pure function placed outside the component — it takes a buffer ref param rather than closing over component state
  - The AIPanel version of parseSSEData doesn't handle partial chunks — this version buffers incomplete lines across calls
  - `sseBufferRef` must be reset to `{ partial: '' }` before starting a new stream to avoid leftover data from previous streams
  - `streamingMessageIdRef` tracks which message in the messages array is being streamed into — needed for updating the correct message as tokens arrive
  - `AgentMessage.isStreaming` flag distinguishes a message still being streamed vs. a completed message — used by UI to show cursor/typing indicator
---

## 2026-02-05 - US-004
- What was implemented: Updated `sendToAgentRegular()` to use SSE streaming via `/api/ai/chat/stream`
- Files changed: `components/AgentControlCenter/index.tsx`
- **Details:**
  - Replaced `fetch → response.json()` with `fetch → ReadableStream → chunk reader` pattern
  - Creates AbortController and stores in `abortControllerRef` for stop generation support
  - Resets `sseBufferRef` before each stream to clear leftover partial data
  - Generates unique streaming message ID (`stream_${Date.now()}`) stored in `streamingMessageIdRef`
  - Creates initial empty streaming message with `isStreaming: true` flag (replaces thinking indicator)
  - Reads chunks via `response.body.getReader()` with `TextDecoder` in a while loop
  - Parses chunks through `parseSSEData()` with buffer ref for partial line handling
  - `token` events: accumulates content string, updates message in-place via `setMessages` map over `msgId`
  - `tool_end` events: accumulates tool results array for final processing
  - `done` event: parses JSON content, handles CADG plans (setPendingCadgPlan), updates routing/agent statuses, processes tool results, saves to DB, finalizes message with full metadata
  - `error` event: throws to be caught by outer catch block
  - AbortError (DOMException) caught separately — keeps partial content, doesn't show error
  - Mid-stream errors show accumulated content + error notice appended
  - Finally block: resets isStreaming, isProcessing, abortControllerRef, streamingMessageIdRef
  - TypeScript: `npx tsc --noEmit` passes with no NEW errors (only pre-existing folderName errors)
- **Learnings for future iterations:**
  - The streaming message uses the `id` field on AgentMessage to update in-place via `setMessages(prev => prev.map(m => m.id === msgId ? ... : m))`
  - Tool results can come from both SSE `tool_end` events (accumulated) and the `done` event metadata — prefer `done` event data when available as it's authoritative
  - AbortError has `error.name === 'AbortError'` and is a DOMException — handle separately from real errors
  - The `done` event content string must be JSON.parse'd — it's the same shape as the old `/api/ai/chat` response body
  - CADG plan detection in streaming is identical to non-streaming — check `data.isGenerative && data.plan?.planId` from parsed done event
  - The function returns early after CADG plan handling to avoid processing as regular response
---
